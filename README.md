# ğŸ¤– Gesture-Based Emoji & Sticker Detection using MediaPipe

## ğŸ“Œ Overview
This project detects **hand gestures** and **facial expressions** in real-time using a webcam,  
then displays a related **sticker or emoji** (e.g., happy face, salute, shh ğŸ¤«, etc.) in a separate window.

It combines **Computer Vision** and **AI-based landmark detection** from **MediaPipe** to create  
an interactive, expressive system that reacts to your movements â€” like a TikTok filter or AR effect.

---

## ğŸ¯ Features
- âœ‹ Real-time hand gesture recognition using **MediaPipe Hands**.  
- ğŸ˜€ Face expression detection using **MediaPipe FaceMesh**.  
- ğŸ¥ Dual-window display:
  - **Camera Feed** â€“ live view with hand/face landmarks.
  - **Sticker Window** â€“ shows the corresponding emoji/sticker.
- ğŸ‘ï¸ Recognizes multiple gestures:
  | Gesture | Description | Sticker |
  |----------|--------------|----------|
  | ğŸ¤« `shh` | Finger on lips | STK-20250409-WA0035.webp |
  | ğŸ‘ `thumb_up` | Thumb raised | STK-20250409-WA0001.webp |
  | ğŸ™Œ `peace` | Both hands raised | STK-20250408-WA0059.webp |
  | ğŸ«¡ `shrug` | Hand near head (salute) | STK-20250207-WA0001.webp |
  | ğŸ˜® `happy` | Mouth open / tongue visible | STK-20241205-WA0004.webp |
  | âœ‹ `nope` | Hand in front | STK-20241126-WA0032.webp |
  | ğŸ¤¦â€â™‚ï¸ `finger_up` | Two fingers near head | STK-20240725-WA0009.webp |

---

## ğŸ§© Technologies Used
- **Python 3.10+**
- **OpenCV** â€“ Video capture & display.
- **MediaPipe** â€“ Hand & face landmark detection.
- **ImageIO** â€“ Load and play `.webp` stickers.
- **NumPy** â€“ Image processing utilities.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Moamenmohamed00/computer-vision.git
cd computer-vision
2ï¸âƒ£ Install dependencies
bash
Copy code
pip install opencv-python mediapipe imageio numpy
3ï¸âƒ£ Run the project
Open proj1.ipynb in Jupyter Notebook or VS Code, then run all cells.

ğŸ–¼ï¸ Folder Structure
bash
Copy code
computer-vision/
â”‚
â”œâ”€â”€ stickers/                  # Folder containing all .webp stickers
â”‚   â”œâ”€â”€ STK-20250409-WA0035.webp
â”‚   â”œâ”€â”€ STK-20250409-WA0001.webp
â”‚   â”œâ”€â”€ STK-20250408-WA0059.webp
â”‚   â”œâ”€â”€ STK-20250207-WA0001.webp
â”‚   â”œâ”€â”€ STK-20241205-WA0004.webp
â”‚   â”œâ”€â”€ STK-20241126-WA0032.webp
â”‚   â””â”€â”€ STK-20240725-WA0009.webp
â”‚
â”œâ”€â”€ proj1.ipynb                # Main notebook file (gesture detection)
â””â”€â”€ README.md                  # Project documentation
ğŸ§  How It Works
The camera feed is captured via OpenCV.

MediaPipe detects 21 hand landmarks and 468 facial landmarks.

Based on relative positions:

If certain fingers are up â†’ detects a gesture.

If mouth or tongue visible â†’ detects an expression.

The system shows the matching .webp sticker on a separate window.

ğŸ¬ Demo
Hereâ€™s an example of the project in action:

Gesture	Output
ğŸ«¡ Hand near head	
ğŸ˜† Mouth open	

ğŸ§‘â€ğŸ’» Author
Moamen Mohamed
ğŸ“ Computer Vision & AI Developer
ğŸ“ Egypt
ğŸ”— GitHub Profile

ğŸ’¡ Future Enhancements
Add sound effects for each gesture ğŸµ

Support for animated 3D stickers (GIF or short MP4)

Integrate body pose tracking (MediaPipe Pose)

Export gestures as short clips for social media apps

ğŸ License
This project is open-source under the MIT License.
